# 1장 아파치 카프카 개요

## 1.1 전체 내용
1장에서는 아파치 카프카로 무엇을 할 수 있을지 살펴본다. 아파치 카프카가 탄생한 배경, 현재 산업계에 어떤 영향을 주고 있는지를 알아본다.


## 1.2 아파치 카프카

아파치 카프카는 여러 대의 서버로 구성된 클러스터에서 대량의 데이터를 처리하는 **분산 메시징 시스템**이다.  
메시지(데이터)를 받고, 받은 메시지를 다른 시스템이나 장치에 보내기 위해 사용된다.  
카프카는 여러 시스템과 장치를 연결하는 중요한 역할을 한다.

카프카는 높은 처리량(high-throughput)과 실시간(real-time) 데이터 처리를 위한 제품으로, 다음과 같은 4가지 특징을 갖는다:

1. **확장성**: 여러 서버로 확장(scale-out) 구성할 수 있기 때문에 데이터 양에 따라 시스템 확장 가능


2. **영속성**: 수신한 데이터를 디스크에 유지할 수 있어서 언제라도 데이터를 읽을 수 있음


3. **유연성**: 연계할 수 있는 제품이 많기 때문에 제품이나 시스템을 연결하는 허브 역할 수행


4. **신뢰성**: 메시지 전달 보증을 할 수 있어, 데이터 분실 걱정이 없음


---

## 1.3 카프카 탄생 배경

카프카는 **링크드인(LinkedIn)** 에서 출발했다.  
링크드인에서 생성되는 대량의 로그를 처리하여 웹사이트 활동을 추적하기 위해 개발되었다.

사용자의 페이지 뷰, 검색 시 키워드 광고 등 다양한 이용 상황을 추적하고, 웹에서 생성되는 대량의 로그를 분석하여 사용자의 웹 상 활동을 모니터링하고 서비스 개선에 활용하기 위한 목적이었다.

빅데이터 활용이 큰 화제가 되면서, 당시 많은 웹 기업들은 웹사이트에서 생성되는 로그를 적극적으로 활용하기 시작했다.


---
### 링크드인이 카프카를 개발하며 실현하고자 한 목표

1. **높은 처리량으로 실시간 처리**
    - 전 세계인들의 방대한 데이터를 실시간 처리하려면 높은 처리량이 필요
    - 사용자의 활동을 신속하게 파악하고, 그에 따라 즉시 피드백하기 위해 실시간 처리가 필수적

2. **임의의 타이밍에 데이터를 읽기**
    - 실시간 처리뿐 아니라, 데이터를 읽는 타이밍을 사용 목적에 따라 다르게 할 수 있도록
    - 일정 시간마다 배치 처리하거나, 방대한 데이터를 전달할 때의 버퍼 역할도 가능해야 함

3. **다양한 제품과 시스템과의 연동**
    - 데이터 소스와 서버/시스템이 여러 개로 분리되어 있어, 다양한 소스에서 데이터를 수집하고 다양한 목적지로 데이터를 전달해야 함
    - e.g. DB, 데이터 웨어하우스, Hadoop 등

4. **메시지를 잃지 않음**
    - 취급하는 메시지의 양이 많더라도 데이터 손실이 없어야 함
    - 중복 데이터가 발생하더라도 손실 없는 처리 우선
    - 데이터 1건마다 엄격한 관리보다는, 처리량과 신뢰성의 균형을 중시


	![img1-3](/chapter01/img/1-3.png)


---
### 카프카 이전의 상용 제품들
링크드인의 요구 사항을 부분적으로 충족하는 제품은 있었으나, 포괄적으로 모두 해결해주는 제품은 없었다. 데이터를 전달하거나 로드할 때 필요한 제품들로 메시지 큐, 로그 수집, ETL 도구가 있다.


해당 제품의 특징을 알아보고, 기존 제품들이 충족하지 못한 부분을 파악할 수 있다.


### 메시지 큐(Message Queue)
한 건의 레코드 단위로 실시간 처리를 할 때 가장 먼저 떠올릴 수 있다. MQ 제품 별로 제공 기능에 차이는 있으나, 아래와 같은 특징들이 링크드인 요구 사항에 맞지 않았다.


1. 강력한 전달 보증은 오버 스펙
    - IBM WebSphere MQ는 메시지 단위로 Transaction을 지원했다. (각 메시지 별로 정확히 한 번 전송됨을 보증, `commit()` 이나 `rollback()` 가능)
	- 그러나 링크드인에서 로그를 다룰 때, 엄격한 transaction 관리는 오버 스펙이다. 
    - 엄격한 관리 대신 높은 처리량이 더 우선 순위가 높았기 때문에 적절하지 않았다.


2. 스케일 아웃이 용이하지 않음
	- 대량 메시지를 처리할 때 여러 대의 서버를 사용해야 할 수 있다(scale-out).
	- 기존 MQ 제품 중에서도 클러스터 구성을 할 수 있는 것들이 있었지만, 실제로는 가용성을 위한 중복 구성이 중점이고, 처리 성능을 높이는 Scale-out을 전제로한 제품이 당시에 존재하지 않았다.


3. 메시지를 대량으로 쌓아둘 수 없음
	- 반드시 메시지를 실시간으로 전송, 소비할 필요는 없었다.
	- 링크드인에서는 메시지를 쌓아 두었다가 배치 처리하는 것도 가정하고 있었다. (ex. 일정량의 데이터가 차면, interval을 두고 데이터 웨어하우스에 전송)
	- 이런 기능을 구현하기 위해서는 메시지가 쌓일(데이터가 축적될) 시간이 충분히 길어야 하는데, 기존 메시지 큐는 쌓아두는 것을 염두에 두지 않아서 이런 목적의 사용을 감당할 수 없었다.



### 로그 수집 시스템

실시간으로 데이터를 수집하는 관점에서 볼 때, 로그 수집을 위한 미들웨어를 떠올릴 수 있다. 

그러나 기존 제품들은 각 프론트엔드 서버가 로그를 중계용 서버에 전송하고, 거기서 로그를 수집하여 DB와 HDFS(Hadoop Distributed File System)에 축적하는 방식으로 동작한다.


따라서, 로그 수집 시스템은 다음과 같은 한계가 있다.


1. HDFS로 데이터를 축적하는 것과 배치 처리만 고려했다.
	- 주로 대량의 로그를 HDFS에 축적하고, 하둡 맵리듀스에서 일괄 처리하는 것이 주목적이었다.
	- 그러나 하둡 말고도 다양한 환경에서 활용하고 동작하기를 원했다.
	- 또한, 데이터 배치 처리와 실시간 처리를 모두 가능하게 만들고 싶었기 때문에 기존 제품은 부족한 점이 많았다.


2. 알기 쉬운 API가 없다.
	- 미들웨어 내에서 구현 사양을 모르면 사용하기 힘들다.
	- 이용하기 쉬운 송수신 API의 필요성이 강하게 느껴지는 상황이었다.


3. 수신하는 쪽이 임의로 메시지를 수신하기 어렵다.
	- Push 모델과 Pull 모델의 차이를 생각해보자
	- 기존의 로그 수집 기반 서버는 Push 모델으로, 서버에서 수신자에게 메시지를 전달했다.
	- 그러나 링크드인에서는 메시지를 다양하게 활용하고 싶었기 때문에 각 수신자가 자신의 속도나 처리 빈도에 따라 수신을 조절하고 싶었다. (결국, Kafka에는 Pull 모델 방식 차용)


### ETL 도구
ETL 도구는 Extract, Transform, Load 의 앞글자를 딴 이름으로, 다음과 같은 특징을 가진다.

| 단계     | 의미        |
| -------- | ---------- | 
| **E - Extract (추출)**   | 원천 시스템(e.g. DB, 로그 파일, API 등)으로부터 데이터를 가져옴           | 
| **T - Transform (변환)** | 가져온 데이터를 원하는 형태로 가공/정제/필터링 (e.g. 형식 변경, 컬럼 추가, 조인 등) | 
| **L - Load (적재)**      | 변환된 데이터를 대상 시스템(e.g. DB, 데이터 웨어하우스 등)에 저장        | 



ETL 도구는 데이터를 파일 단위로 다루면서, 배치 처리 등을 위해 사용된다. 그러나 링크드인은 데이터를 레코드 단위로 실시간 처리하는 기능도 매우 필요했기 때문에 적절하지 않았다.


또한, Push 모델의 단점이 ETL 도구에도 해당한다. 소비를 원하는 임의의 타이밍에 읽을 수 없다는 한계도 있었다.


---
## 1.4 카프카로 링크드인 요구 사항 실현하기
링크드인의 각 요구사항을 어떻게 실현했는지 mapping한 결과를 볼 수 있다.


![img1-7](/chapter01/img/1-7.png)


## 1.4.1 메시징 모델과 스케일 아웃
카프카는 다음과 같은 요구 사항을 만족시키기 위해 메시징 모델을 채용했다.


1. 높은 처리량을 실시간으로 처리
2. 임의의 타이밍에 데이터를 읽는다.
3. 다양한 제품과 시스템에 쉽게 연동된다.


일반적으로 메시징 모델은 다음과 같은 세 가지 요소로 구성된다.


1. `Producer`: 메시지 생산자
2. `Broker`: 메시지 수집/전달 역할
3. `Consumer`: 메시지 소비자


카프카 메시징 모델은 기존의 메시징 모델인 큐잉 모델과 Pub/Sub 모델 둘의 특징을 겸비한 형태로 만들어졌다.


### 큐잉 모델
브로커 안에 큐를 준비해, Producer의 메시지가 큐에 담기고, Consumer가 큐에서 메시지를 꺼내어 소비한다.


하나의 큐에 대해 컨슈머가 여러 개 존재할 수 있어서, 컨슈머를 늘리며 처리를 확장할 수 있다. (기본적인 큐잉 모델은) 한 컨슈머가 큐에서 메시지를 꺼내면, 그 컨슈머에서만 처리된다.



### Pub/Sub 메시징 모델
해당 모델은 메시지 생산자를 Publisher, 메시지 소비자를 Subscriber라고 한다. Publisher는 직접 메시지를 전달하는게 아니라, Broker를 통해 전달한다.


Broker에 있는 Topic이라는 카테고리 안에 메시지를 등록하면, Subscriber가 등록된 토픽을 선택하여 메시지를 받는다. (여러 subscriber가 동일한 토픽을 구독하면 동일한 메시지를 받을 수 있음)


### Producer, Consumer 사이에 Broker를 끼우는 장점
큐잉 모델이든, Pub/Sub 모델이든 모두 브로커를 사이에 끼우는 형태의 모델인데, Broker를 사이에 끼우면 변경에 강한 시스템 아키텍처를 만들 수 있다는 장점이 있다.


- Producer/Consumer 간 의존성 없음
	- 서로를 몰라도 Broker를 통해 메시지를 송수신하면 된다.
	- 시스템 토폴로지 구성을 단순하게 만든다.


- Producer/Consumer 증감에 대응하기 쉬움
	- 네트워크 토폴로지 변경에 강하다.
	- 서로의 존재를 모르기 때문에 양측 증감이 자유롭다.
	- 장애 상황에서도 서로 의존성이 없고, 장애가 난 노드만큼 복구해서 증감하기 쉬워서 유연하게 운영할 수 있다.


		![img1-12](/chapter01/img/1-12.png)

		+ 위와 반대로, Producer와 Consumer가 서로를 안다는 것은 큰 단점이다.
		+ 서로 의존성이 있다는 것 == 서로 연결 관계가 direct로 묶여있다는 것 == 장애 상황에 장애가 전파된다는 것
		+ 연결 관계 관리나 필요에 따른 증감이 어렵다. (관리 비용 상승)



## 1.4.2 카프카 메시징 모델
높은 처리량을 위한 확장성 있는 구성이 중요하기 때문에 아래 두 모델의 특징을 차용했다.


- 큐잉 모델: 여러 컨슈머가 분산 처리로 메시지를 소비
- Pub/Sub 모델: 여러 Subscriber에 동일한 메시지를 전달할 수 있고 토픽 기반으로 전달


또한, 컨슈머를 확장 구성할 수 있도록 Consumer Group이라는 개념을 도입했다.


![img1-13](/chapter01/img/1-13.png)


- 여러 컨슈머가 동일 토픽을 분산하여 메시지를 읽음으로서 처리의 확장성을 담보한다.
	- 그러나 이로 인해 생기는 중복 메시지 소비 문제 & 순서 보장 문제가 있기 때문에 주의해야 한다.
- 브로커가 하나라면 병목이 될 수 있어서 브로커도 복수 구성으로 동작하도록 설계되었다.
- 결과적으로, 전체적 확장이 가능한 구조이다.


## 1.4.3 디스크로의 데이터 영속화
카프카는 브로커에 보낸 메시지를 디스크에 영속화하여 다음 두 가지 요구를 만족시킨다.


1. 임의의 타이밍에 데이터 읽기
2. 메시지를 잃지 않는다


기본적으로 장기 보존을 가정하지 않는 다른 메시지 큐와 달리, 배치 처리 등 다양한 장기 보관 시나리오도 가능해야한다. 이를 디스크에 영속화하는 방식으로 구현했다.


기본적으로 Disk I/O가 느리다는 인식이 있지만, 카프카는 Disk에 씀에도 불구하고 높은 처리량을 제공한다는 특징이 있다. 이 때문에 Storage System 처럼 여기기도 한다. (ex. 로그 축적)


>
> 카프카에서 영속화 목적?
>
> - 영속화(Persistence)의 의미
> 	
> 	- 단순히 ‘디스크에 남겨 데이터 무손실을 보장’하는 목적만은 아니다.
> 	- 브로커 메모리에 적재되면 곧바로 송신 완료 처리가 된다.(디스크 flush는 OS에 위임)
>
> - 내장애성(내결함성) 확보를 반드시 영속화로 이루려는 목적은 아니다. 오히려 replica를 통한 복구 의도가 내재되어 있다.
> 
> 	- 단일 브로커 장애 시 즉시 손실 방지를 위해 Replication 구조 사용
>	- 최소 복제본(replica)이 살아 있으면 소비자(consumer) 접근 허용
>
> - 조정 가능한 디스크 flush 전략
> 	- OS 기본 flush 대신, 카프카 파라미터로 디스크 쓰기 주기 설정 가능
> 	- 사용 시나리오에 맞춰 장애 허용 범위와 성능을 균형 있게 조정
>



## 1.4.4 이해하기 쉬운 API 제공
카프카는 다양한 제품과 시스템에 쉽게 연동할 수 있는 Connect API 를 제공한다. 또한, API를 기반으로 카프카에 접속하기 위한 프레임워크 Kafka Connect도 제공한다.


![img1-14](/chapter01/img/1-14.png)



## 1.4.5 전달 보증
카프카의 전달 보증 기능은 다음과 같이 3가지가 있다.


| 전달 보장  | 설명    | 재전송 유무   | 중복 삭제     | 비고       |
| ------- | -------- | ---------- | --------------- | -------------- |
| `At Most Once`  | 메시지를 최대 한 번만 전달. 전송 실패 시 재시도하지 않음   | 없음   | 해당 없음  | 손실 가능성 존재    |
| `At Least Once`  | 메시지를 최소 한 번 이상 전달. 확실한 전달을 위해 실패 시 재전송  | 있음   | 없음   | 메시지 중복 수신될 가능성 있고, 상실되지 않음 |
| `Exactly Once`  | 트랜잭션 및 idempotent 프로듀서를 통해 메시지를 정확히 한 번만 전달 보장  | 내부적으로 재전송 가능하나 중복 소비 방지 | 있음  | 확실하게 메시지가 도달하지만, 구현 복잡도 높고 성능 저하 위험 |


카프카 개발 초기에는 성능을 중시했기 때문에 Exactly Once 수준의 보증은 미루고 최소한 메시지 분실을 방지하자는 At Least Once 수준으로 전달을 보증했다.


### At Least Once
- Ack와 Offset Commit 이라는 개념을 도입했다.
- Ack: Broker가 메시지를 수신했을 때 Producer에게 수신 완료했다는 응답을 보내는 것 (Ack 받지 못한 경우 재전송 판단)
- Offset: Consumer가 Broker로부터 메시지를 받을 때, 어디까지 받았는지를 관리한다.
- Offset Commit: 전달 범위 보증 구조 (어디까지 읽었는지 확인하고 기록 update, 어디부터 재전송해야하는지 판단 기준이 됨)


### Exactly Once
- 카프카에 트랜잭션 개념을 도입하여 전달을 보증하는 메커니즘
- 쌍방간의 실현이 모두 필요 (Producer-Broker / Broker-Consumer)
	- Producer-Broker: 양측 모두에서 시퀀스 번호 관리하여 중복 실행 제거
	- Broker-Consumer: 컨슈머에 대해 트랜잭션 범위 해석, 트랜잭션 중단 시, 중단까지의 처리 파기(rollback)
- 이런 시스템을 상류 upstream / 하류 downstream 로 나눠서 부른다.
- 따라서, 카프카 단독으로는 전달 보증을 실현하긴 어렵지만, 트랜잭션 관리 메커니즘을 통해 상류와 하류 시스템 사이에서 필요한 상태 관리가 갖추어지면 전달이 보증될 수 있다.


	![img1-17](/chapter01/img/1-17.png)


	![img1-18](/chapter01/img/1-18.png)


---
## 1.5 카프카의 확산
카프카 출시 이후, 다양한 클라우드 서비스에도 영향을 주고 있다. 클라우드 환경에서 메시지를 전달하기 위한 다양한 카프카 관리 서비스들을 제공하고 있다. (e.g. AWS, GCP)


카프카를 사용하는 기업은 점점 확산되고 있으며, 현재는 수 많은 기업들이 적극적으로 사용하고 있다. 5장에서 카프카 실제 사용 사례에 대해서 다룬다.



---
## 1.6 Summary
카프카의 개요와 탄생 배경은 링크드인으로 부터 시작했다.
링크드인에서 원했던 요구 사항, 개발 배경과 동기가 구체적으로 어떤 아파치 카프카의 특징과 기능으로 탄생했는지 연결해서 볼 수 있었다.


카프카는 스케일 아웃에 의한 높은 처리량을 실현하면서, 큐잉 모델과 펍/섭 메시징 모델을 조합한 유연한 구조이다.


2장에서는 카프카 아키텍처를 다루며 기본적인 사양을 볼 수 있다.