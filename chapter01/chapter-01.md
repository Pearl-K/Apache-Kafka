# 1장 아파치 카프카 개요

## 1.2 아파치 카프카

아파치 카프카는 여러 대의 분산 서버에서 대량의 데이터를 처리하는 **분산 메시징 시스템**이다.  
메시지(데이터)를 받고, 받은 메시지를 다른 시스템이나 장치에 보내기 위해 사용된다.  
카프카는 여러 시스템과 장치를 연결하는 중요한 역할을 한다.

카프카는 높은 처리량(high-throughput)과 실시간(real-time) 데이터 처리를 위한 제품으로, 다음과 같은 4가지 특징을 갖는다:

1. **확장성**: 여러 서버로 확장(scale-out) 구성할 수 있기 때문에 데이터 양에 따라 시스템 확장 가능


2. **영속성**: 수신한 데이터를 디스크에 유지할 수 있어서 언제라도 데이터를 읽을 수 있음


3. **유연성**: 연계할 수 있는 제품이 많기 때문에 제품이나 시스템을 연결하는 허브 역할 수행


4. **신뢰성**: 메시지 전달 보증을 할 수 있어, 데이터 분실 걱정이 없음


---

## 1.3 카프카 탄생 배경

카프카는 **링크드인(LinkedIn)** 에서 출발했다.  
링크드인에서 생성되는 대량의 로그를 처리하여 웹사이트 활동을 추적하기 위해 개발되었다.

사용자의 페이지 뷰, 검색 시 키워드 광고 등 다양한 이용 상황을 추적하고, 웹에서 생성되는 대량의 로그를 분석하여 사용자의 웹 상 활동을 모니터링하고 서비스 개선에 활용하기 위한 목적이었다.

빅데이터 활용이 큰 화제가 되면서, 당시 많은 웹 기업들은 웹사이트에서 생성되는 로그를 적극적으로 활용하기 시작했다.


---
### 링크드인이 카프카를 개발하며 실현하고자 한 목표

1. **높은 처리량으로 실시간 처리**
    - 전 세계인들의 방대한 데이터를 실시간 처리하려면 높은 처리량이 필요함
    - 사용자의 활동을 신속하게 파악하고, 그에 따라 즉시 피드백하기 위해 실시간 처리가 필수적임

2. **임의의 타이밍에 데이터를 읽기**
    - 실시간 처리뿐 아니라, 데이터를 읽는 타이밍을 사용 목적에 따라 다르게 할 수 있도록
    - 일정 시간마다 배치 처리하거나, 방대한 데이터를 전달할 때의 버퍼 역할도 가능해야 함

3. **다양한 제품과 시스템과의 연동**
    - 데이터 소스와 서버/시스템이 여러 개로 분리되어 있어, 다양한 소스에서 데이터를 수집하고 다양한 목적지로 데이터를 전달해야 함
    - 예: DB, 데이터 웨어하우스, Hadoop 등

4. **메시지를 잃지 않음**
    - 취급하는 메시지의 양이 많더라도 데이터 손실이 없어야 함
    - 중복 데이터가 발생하더라도 손실 없는 처리 우선
    - 데이터 1건마다 엄격한 관리보다는, 처리량과 신뢰성의 균형을 중시


![img1-3](/chapter01/img/1-3.png)


---
### 카프카 이전의 상용 제품들
링크드인의 요구 사항을 부분적으로 충족하는 제품은 있었으나, 포괄적으로 모두 해결해주는 제품은 없었다. 데이터를 전달하거나 로드할 때 필요한 제품들로 메시지 큐, 로그 수집, ETL 도구가 있다.


해당 제품의 특징을 알아보고, 기존 제품들이 충족하지 못한 부분을 파악하자.


### 메시지 큐(Message Queue)
한 건의 레코드 단위로 실시간 처리를 할 때 가장 먼저 떠올릴 수 있다. MQ 제품 별로 제공 기능에 차이는 있으나, 아래와 같은 특징들이 링크드인 요구 사항에 맞지 않았다.


1. 강력한 전달 보증은 오버 스펙
    - IBM WebSphere MQ는 메시지 단위로 Transaction을 지원했다. (각 메시지 별로 정확히 한 번 전송됨을 보증, `commit()` 이나 `rollback()` 가능)
	- 그러나 링크드인에서 로그를 다룰 때, 엄격한 transaction 관리는 오버 스펙이다. 
    - 엄격한 관리 대신 높은 처리량이 더 우선 순위가 높았기 때문에 적절하지 않았다.


2. 스케일 아웃이 용이하지 않음
	- 대량 메시지를 처리할 때 여러 대의 서버를 사용해야 할 수 있다(scale-out).
	- 기존 MQ 제품 중에서도 클러스터 구성을 할 수 있는 것들이 있었지만, 실제로는 가용성을 위한 중복 구성이 중점이고, 처리 성능을 높이는 Scale-out을 전제로한 제품이 당시에 존재하지 않았다.


3. 메시지를 대량으로 쌓아둘 수 없음
	- 반드시 메시지를 실시간으로 전송, 소비할 필요는 없었다.
	- 링크드인에서는 메시지를 쌓아 두었다가 배치 처리하는 것도 가정하고 있었다. (ex. 일정량의 데이터가 차면, interval을 두고 데이터 웨어하우스에 전송)
	- 이런 기능을 구현하기 위해서는 메시지가 쌓일(데이터가 축적될) 시간이 충분히 길어야 하는데, 기존 메시지 큐는 쌓아두는 것을 염두에 두지 않아서 이런 목적의 사용을 감당할 수 없었다.



### 로그 수집 시스템

실시간으로 데이터를 수집하는 관점에서 볼 때, 로그 수집을 위한 미들웨어를 떠올릴 수 있다. 

그러나 기존 제품들은 각 프론트엔드 서버가 로그를 중계용 서버에 전송하고, 거기서 로그를 수집하여 DB와 HDFS(Hadoop Distributed File System)에 축적하는 방식으로 동작한다.


따라서, 로그 수집 시스템은 다음과 같은 한계가 있다.


1. HDFS로 데이터를 축적하는 것과 배치 처리만 고려했다.
	- 주로 대량의 로그를 HDFS에 축적하고, 하둡 맵리듀스에서 일괄 처리하는 것이 주목적이었다.
	- 그러나 하둡 말고도 다양한 환경에서 활용하고 동작하기를 원했다.
	- 또한, 데이터 배치 처리와 실시간 처리를 모두 가능하게 만들고 싶었기 때문에 기존 제품은 부족한 점이 많았다.


2. 알기 쉬운 API가 없다.
	- 미들웨어 내에서 구현 사양을 모르면 사용하기 힘들다.
	- 이용하기 쉬운 송수신 API의 필요성이 강하게 느껴지는 상황이었다.


3. 수신하는 쪽이 임의로 메시지를 수신하기 어렵다.
	- Push 모델과 Pull 모델의 차이를 생각해보자
	- 기존의 로그 수집 기반 서버는 Push 모델으로, 서버에서 수신자에게 메시지를 전달했다.
	- 그러나 링크드인에서는 메시지를 다양하게 활용하고 싶었기 때문에 각 수신자가 자신의 속도나 처리 빈도에 따라 수신을 조절하고 싶었다. (결국, Kafka에는 Pull 모델 방식 차용)


### ETL 도구
ETL 도구는 Extract, Transform, Load 의 앞글자를 딴 이름으로, 다음과 같은 특징을 가진다.

| 단계     | 의미        |
| -------- | ---------- | 
| **E - Extract (추출)**   | 원천 시스템(e.g. DB, 로그 파일, API 등)으로부터 데이터를 가져옴           | 
| **T - Transform (변환)** | 가져온 데이터를 원하는 형태로 가공/정제/필터링 (e.g. 형식 변경, 컬럼 추가, 조인 등) | 
| **L - Load (적재)**      | 변환된 데이터를 대상 시스템(e.g. DB, 데이터 웨어하우스 등)에 저장        | 



ETL 도구는 데이터를 파일 단위로 다루면서, 배치 처리 등을 위해 사용된다. 그러나 링크드인은 데이터를 레코드 단위로 실시간 처리하는 기능도 매우 필요했기 때문에 적절하지 않았다.


또한, Push 모델의 단점이 ETL 도구에도 해당한다. 소비를 원하는 임의의 타이밍에 읽을 수 없다는 한계도 있었다.


---
## 1.4 카프카로 링크드인 요구 사항 실현하기
링크드인의 각 요구사항을 어떻게 실현했는데 mapping한 결과를 볼 수 있다.


![img1-7](/chapter01/img/1-7.png)


### 큐잉 모델



### Pub/Sub 메시징 모델


### Producer, Consumer 사이에 Broker를 끼우는 장점
