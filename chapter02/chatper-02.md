# 2장 카프카 기초
## 2.1 이 장의 내용
이 장의 핵심 내용은 다음과 같다.

1. 카프카의 메시지 송수신 기본 구조
2. 시스템 구성
3. 분산 메시징을 위한 구조
4. 데이터 견고함을 담보하는 복제의 구조


카프카를 주로 이용하는 메시징 시스템의 사용자 측면에서는 1~3번을 위주로, 카프카를 이용한 플랫폼을 설계, 구축, 운용하는 엔지니어는 4의 내용도 포함하여 파악하는 것이 좋다.


---
## 2.2 메시지 송수신 기본
![img2-1](/chapter02/img/2-1.png)


카프카의 주요 구성 요소 5가지


1. 브로커(Broker): 데이터를 수신, 전달하는 서비스
2. 메시지(Message): 카프카에서 다루는 데이터의 최소 단위, 카프카가 중계하는 로그 한 줄, 센서 데이터 등이 여기 해당한다. 메시지는 K, V를 갖게되며 나중에 언급할 메시지 전송 파티셔닝에 이용된다.
3. 프로듀서(Producer): 데이터의 생산자이자 브로커에 메시지를 보내는 애플리케이션
4. 컨슈머(Consumer): 브로커에서 메시지를 취득하는 애플리케이션
5. 토픽(Topic): 메시지를 토픽에 해당하는 종류 별로 관리하는 스토리지를 말한다. 브로커에 배치되어 관리된다. 프로듀서와 컨슈머는 특정 토픽을 지정하여 메시지를 송수신하며 단일 카프카 클러스터에서 여러 종류의 메시지를 중계한다.


---
## 2.3 시스템 구성
### 브로커 Broker
브로커는 하나의 서버(or 인스턴스) 당 하나의 데몬 프로세스로 동작하여 메시지 수신/전달 요청을 받아들인다.


이를 여러 대의 클러스터로 구성할 수 있으며, 브로커(리소스)를 추가하여 scale-out 가능하다.


브로커에서 받은 데이터는 모두 Disk 내보내기(영속화)가 이루어져 디스크의 총 용량에 따라 장기간 데이터를 보존할 수 있다.


### Producer API / Consumer API
프로듀서/컨슈머를 구현하는 기능은 브로커로 데이터를 보내고, 받기 위한 라이브러리로 제공된다.


프로듀서를 구현하기 위한 API를 프로듀서 API, 컨슈머를 구현하기 위한 API를 컨슈머 API라고 한다.


프로듀서, 컨슈머는 브로커처럼 서비스(데몬 프로세스)로 작동하는 프로그램이 아니고, 각각의 API가 자바로 제공되는 형태이다.


### 프로듀서 Producer
프로듀서는 프로듀서 API를 이용하여 브로커에 데이터를 송신하기 위해 구현된 애플리케이션이다.


실제 사용할 때 로그 전송 및 미들웨어와 연동하여 동작하기 때문에 프로듀서 API를 내포한 도구, 미들웨어 등을 통해 이용할 수도 있다.


프로듀서 기능을 내장하거나, third-party 플러그인 제휴를 통해 제공하는 OSS 도구 종류 예시는 다음과 같다.
- Apache Log4j (Kafka Appender), Apache Flume, Fluentd, Logstash



### 컨슈머 Consumer
컨슈머 API를 통해 브로커에서 메시지를 취득하도록 구현된 애플리케이션이다. 브로커는 앞서 말한 대로 메시지를 disk에 영속화하기 때문에, disk에 보관되어 있는 동안 메시지를 취득할 수 있다.


일정 기간 데이터를 축적한 스토리지에서 데이터를 추출하든, 실시간 처리에 사용하든 원하는 형태로 소비할 수 있다.


다양한 OSS에서 컨슈머 기능을 내장하여 카프카 연계가 가능하게 만들어져있다.
- Apache Spark, Apache Samza, Apache Flink, Apache Flume, Fluentd, Logstash



### PUSH 모델, PULL 모델
Producer -> Broker -> Consumer 흐름으로 이동할 때, 두 노드 사이에 메시지 전달을 어느 쪽에서 발생시킬지 주체를 알아보자.


1. Producer -> Broker (PUSH)
프로듀서가 주체가 되어 브로커에 메시지 전송


2. Broker -> Consumer (PULL)
컨슈머에서의 패치 요청을 계기로 메시지 송신


2번의 흐름을 PULL 모델로 하여 얻을 수 있는 시스템 운영 상 장점이 많다.


컨슈머 시스템이 고장나거나 유지 보수로 정지된 경우에도 브로커에 미치는 영향이 적다.


만약, 해당 흐름이 PUSH 형으로 동작했다면, 컨슈머가 중단되거나 상태 이상일 때 대응을 매번 브로커에서 실시해야 한다.


이는 카프카를 겅유하는 메시지와 후속 시스템이 많을수록 시스템 운용 부하와 성능 부하를 증가시킬 것이다.


또한, Consumer의 증감에도 Broker가 개별적으로 대응해야하는 것이 줄어든다. 후속 시스템의 확장과 축소가 쉬워진다는 의미이다. (컨슈머가 각자 주체적으로 데이터를 수신, 진행 관리를 하기 때문)



### 주키퍼 Zookeeper
카프카 브로커에서 분산 처리 관리 도구로 Apache Zookeeper가 필요하다. 주키퍼는 하둡 등 병렬 분산 처리용 OSS에 있어서 설정 관리, 이름 관리, 동기화를 위한 잠금 관리를 하는 구조로 자주 사용된다.


카프카에서는 "분산 메시징의 메타 데이터(topic, partition 등) 관리하는 구성 요소"로 기능한다. 주키퍼 클러스터(주키퍼 앙상블)의 구조는 3, 5 등의 홀수로 구성하는 것이 일반적이다.



### 카프카 클라이언트
토픽 작성 등, 카프카 동작과 운영 상에 필요한 조작을 실행하는 서버이다. (메시지 송수신 처리 X)


### 카프카 클러스터
카프카는 여러 대의 브로커 서버, 주키퍼 서버로 이루어진 클러스터링을 제공한다.



---
## 2.4 분산 메시징을 위한 구조
![img2-3](/chapter02/img/2-3.png)


### 파티션 Partition
토픽에 대한 대량의 메시지 입출력을 지원하기 위해, 데이터를 읽고 쓰는 것이 파티션이라는 단위로 분할되어 있다.


토픽을 구성하는 파티션은 브로커 클러스터 안에 분산 배치되어 프로듀서에서 메시지 수신, 컨슈머로의 배달을 분산해서 실시하여 하나의 토픽에 대한 대규모 데이터 수신과 전달을 지원한다.


### 컨슈머 그룹 Consumer Group
카프카는 downstream 에서 분산 스트림도 고려하여 설계되어 있다. 단일 애플리케이션 안에서 여러 컨슈머가 단일 토픽이나 여러 파티션에서 메시지를 취득할 수 있는 컨슈머 그룹 개념이 존재한다.


카프카 클러스터 전체에서 global ID를 컨슈머 그룹 전체가 공유하고, 여러 컨슈머는 자신이 소속한 컨슈머 그룹을 식별한다. 해당 컨슈머 그룹에 따라 읽을 파티션을 분류하고 재시도를 제어한다.


### 오프셋 Offset
각 파티션에서 수신한 메시지에는 각각 일련번호가 부여되어 있다. 파티션 단위로 메시지 위치를 나타내는 offset이라는 개념이다.


이 offset 관리 정보를 이용해 컨슈머가 취득하는 메시지의 범위와 재시도를 제어할 수 있다.


제어에 사용되는 오프셋의 종류들은 다음과 같다.
- Log-End-Offset(LEO): 파티션 데이터의 끝을 나타낸다.
- Current Offset: 컨슈머가 어디까지 메시지를 읽었는지를 나타낸다.
- Commit Offset: 컨슈머가 어디까지 커밋했는지를 나타낸다.


> LEO는 브로커에 의해 파티션 관련 정보로 관리되고 업데이트된다. 
>
> Commit Offset은 컨슈머 그룹마다 보관되어 관리, 업데이트 된다.
>
> Current Offset은 컨슈머에서 데이터 취득이 일어나면 업데이트된다.


![img2-4](/chapter02/img/2-4.png)


Commit Offset은 컨슈머로부터 여기까지 오프셋을 처리했다고 확인하는 커밋 요청을 계기로 업데이트된다. 특정 토픽에 대해 여러 컨슈머 그룹이 메시지를 취득하는 경우, Commit Offset도 컨슈머 그룹의 숫자만큼 존재한다.



---
## 2.4.1 메시지 송수신



---
## 2.4.2 컨슈머의 롤백



---
## 2.4.3 메시지 전송 시 파티셔닝






---
## 2.5 데이터의 견고성을 높이는 복제 구조


---
## 2.6 정리
다음은 2장에서 정리한 전체 카프카 구성도이다.


![img2-15](/chapter02/img/2-15.png)


위 내용을 바탕으로 카프카의 특징과 장점을 요약하면 다음과 같다.


1. Scale-out 구성: 중계 브로커를 증대하여 전체 처리량을 늘릴 수 있다.
2. 데이터의 Disk 영속화: 장기간의 과거 데이터도 저장, 재취득 가능
3. 다양한 연계 제품: 프로듀서/컨슈머 API를 구현한 다양한 OSS 존재
4. 메시지 도달 보증: Ack 와 Offset commit 으로 메시지가 제대로 송수신되었음을 확인하고, 실패 시 재시도를 허용한다.