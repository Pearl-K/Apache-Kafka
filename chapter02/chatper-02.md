# 2장 카프카 기초
## 2.1 이 장의 내용
이 장의 핵심 내용은 다음과 같다.

1. 카프카의 메시지 송수신 기본 구조
2. 시스템 구성
3. 분산 메시징을 위한 구조
4. 데이터 견고함을 담보하는 복제의 구조


카프카를 주로 이용하는 메시징 시스템의 사용자 측면에서는 1~3번을 위주로, 카프카를 이용한 플랫폼을 설계, 구축, 운용하는 엔지니어는 4의 내용도 포함하여 파악하는 것이 좋다.


---
## 2.2 메시지 송수신 기본
![img2-1](/chapter02/img/2-1.png)


카프카의 주요 구성 요소 5가지


1. 브로커(Broker): 데이터를 수신, 전달하는 서비스
2. 메시지(Message): 카프카에서 다루는 데이터의 최소 단위, 카프카가 중계하는 로그 한 줄, 센서 데이터 등이 여기 해당한다. 메시지는 K, V를 갖게되며 나중에 언급할 메시지 전송 파티셔닝에 이용된다.
3. 프로듀서(Producer): 데이터의 생산자이자 브로커에 메시지를 보내는 애플리케이션
4. 컨슈머(Consumer): 브로커에서 메시지를 취득하는 애플리케이션
5. 토픽(Topic): 메시지를 토픽에 해당하는 종류 별로 관리하는 스토리지를 말한다. 브로커에 배치되어 관리된다. 프로듀서와 컨슈머는 특정 토픽을 지정하여 메시지를 송수신하며 단일 카프카 클러스터에서 여러 종류의 메시지를 중계한다.


---
## 2.3 시스템 구성
### 브로커 Broker
브로커는 하나의 서버(or 인스턴스) 당 하나의 데몬 프로세스로 동작하여 메시지 수신/전달 요청을 받아들인다.


이를 여러 대의 클러스터로 구성할 수 있으며, 브로커(리소스)를 추가하여 scale-out 가능하다.


브로커에서 받은 데이터는 모두 Disk 내보내기(영속화)가 이루어져 디스크의 총 용량에 따라 장기간 데이터를 보존할 수 있다.


### Producer API / Consumer API
프로듀서/컨슈머를 구현하는 기능은 브로커로 데이터를 보내고, 받기 위한 라이브러리로 제공된다.


프로듀서를 구현하기 위한 API를 프로듀서 API, 컨슈머를 구현하기 위한 API를 컨슈머 API라고 한다.


프로듀서, 컨슈머는 브로커처럼 서비스(데몬 프로세스)로 작동하는 프로그램이 아니고, 각각의 API가 자바로 제공되는 형태이다.


### 프로듀서 Producer
프로듀서는 프로듀서 API를 이용하여 브로커에 데이터를 송신하기 위해 구현된 애플리케이션이다.


실제 사용할 때 로그 전송 및 미들웨어와 연동하여 동작하기 때문에 프로듀서 API를 내포한 도구, 미들웨어 등을 통해 이용할 수도 있다.


프로듀서 기능을 내장하거나, third-party 플러그인 제휴를 통해 제공하는 OSS 도구 종류 예시는 다음과 같다.
- Apache Log4j (Kafka Appender), Apache Flume, Fluentd, Logstash



### 컨슈머 Consumer
컨슈머 API를 통해 브로커에서 메시지를 취득하도록 구현된 애플리케이션이다. 브로커는 앞서 말한 대로 메시지를 disk에 영속화하기 때문에, disk에 보관되어 있는 동안 메시지를 취득할 수 있다.


일정 기간 데이터를 축적한 스토리지에서 데이터를 추출하든, 실시간 처리에 사용하든 원하는 형태로 소비할 수 있다.


다양한 OSS에서 컨슈머 기능을 내장하여 카프카 연계가 가능하게 만들어져있다.
- Apache Spark, Apache Samza, Apache Flink, Apache Flume, Fluentd, Logstash



### PUSH 모델, PULL 모델
Producer -> Broker -> Consumer 흐름으로 이동할 때, 두 노드 사이에 메시지 전달을 어느 쪽에서 발생시킬지 주체를 알아보자.


1. Producer -> Broker (PUSH)
프로듀서가 주체가 되어 브로커에 메시지 전송


2. Broker -> Consumer (PULL)
컨슈머에서의 패치 요청을 계기로 메시지 송신


2번의 흐름을 PULL 모델로 하여 얻을 수 있는 시스템 운영 상 장점이 많다.


컨슈머 시스템이 고장나거나 유지 보수로 정지된 경우에도 브로커에 미치는 영향이 적다.


만약, 해당 흐름이 PUSH 형으로 동작했다면, 컨슈머가 중단되거나 상태 이상일 때 대응을 매번 브로커에서 실시해야 한다.


이는 카프카를 겅유하는 메시지와 후속 시스템이 많을수록 시스템 운용 부하와 성능 부하를 증가시킬 것이다.


또한, Consumer의 증감에도 Broker가 개별적으로 대응해야하는 것이 줄어든다. 후속 시스템의 확장과 축소가 쉬워진다는 의미이다. (컨슈머가 각자 주체적으로 데이터를 수신, 진행 관리를 하기 때문)



### 주키퍼 Zookeeper
카프카 브로커에서 분산 처리 관리 도구로 Apache Zookeeper가 필요하다. 주키퍼는 하둡 등 병렬 분산 처리용 OSS에 있어서 설정 관리, 이름 관리, 동기화를 위한 잠금 관리를 하는 구조로 자주 사용된다.


카프카에서는 "분산 메시징의 메타 데이터(topic, partition 등) 관리하는 구성 요소"로 기능한다. 주키퍼 클러스터(주키퍼 앙상블)의 구조는 3, 5 등의 홀수로 구성하는 것이 일반적이다.



### 카프카 클라이언트
토픽 작성 등, 카프카 동작과 운영 상에 필요한 조작을 실행하는 서버이다. (메시지 송수신 처리 X)


### 카프카 클러스터
카프카는 여러 대의 브로커 서버, 주키퍼 서버로 이루어진 클러스터링을 제공한다.



---
## 2.4 분산 메시징을 위한 구조
![img2-3](/chapter02/img/2-3.png)


### 파티션 Partition
토픽에 대한 대량의 메시지 입출력을 지원하기 위해, 데이터를 읽고 쓰는 것이 파티션이라는 단위로 분할되어 있다.


토픽을 구성하는 파티션은 브로커 클러스터 안에 분산 배치되어 프로듀서에서 메시지 수신, 컨슈머로의 배달을 분산해서 실시하여 하나의 토픽에 대한 대규모 데이터 수신과 전달을 지원한다.


### 컨슈머 그룹 Consumer Group
카프카는 downstream 에서 분산 스트림도 고려하여 설계되어 있다. 단일 애플리케이션 안에서 여러 컨슈머가 단일 토픽이나 여러 파티션에서 메시지를 취득할 수 있는 컨슈머 그룹 개념이 존재한다.


카프카 클러스터 전체에서 global ID를 컨슈머 그룹 전체가 공유하고, 여러 컨슈머는 자신이 소속한 컨슈머 그룹을 식별한다. 해당 컨슈머 그룹에 따라 읽을 파티션을 분류하고 재시도를 제어한다.


### 오프셋 Offset
각 파티션에서 수신한 메시지에는 각각 일련번호가 부여되어 있다. 파티션 단위로 메시지 위치를 나타내는 offset이라는 개념이다.


이 offset 관리 정보를 이용해 컨슈머가 취득하는 메시지의 범위와 재시도를 제어할 수 있다.


제어에 사용되는 오프셋의 종류들은 다음과 같다.
- Log-End-Offset(LEO): 파티션 데이터의 끝을 나타낸다.
- Current Offset: 컨슈머가 어디까지 메시지를 읽었는지를 나타낸다.
- Commit Offset: 컨슈머가 어디까지 커밋했는지를 나타낸다.


> LEO는 브로커에 의해 파티션 관련 정보로 관리되고 업데이트된다. 
>
> Commit Offset은 컨슈머 그룹마다 보관되어 관리, 업데이트 된다.
>
> Current Offset은 컨슈머에서 데이터 취득이 일어나면 업데이트된다.


![img2-4](/chapter02/img/2-4.png)


Commit Offset은 컨슈머로부터 여기까지 오프셋을 처리했다고 확인하는 커밋 요청을 계기로 업데이트된다. 특정 토픽에 대해 여러 컨슈머 그룹이 메시지를 취득하는 경우, Commit Offset도 컨슈머 그룹의 숫자만큼 존재한다.



---
## 2.4.1 메시지 송수신
메시지를 송수신할 때, 반드시 하나 단위일 필요는 없다. 송수신 처리량을 늘리기 위해 축적한 후에 처리할 수도 있다.


![img-5](/chapter02/img/2-5.png)


프로듀서가 토픽의 파티션에 메시지를 보낼 때, 기본적으로는 하나씩 가지만, 프로듀서의 메모리를 이용해서 축적해서 보낼 수 있다.

이때 트리거를 두 가지 설정할 수 있는데, 하나는 설정한 크기까지 축적되면 보내지게 지정하는 것과, 다른 하나는 특정 시간이 지날 때까지 기다렸다가 쌓인 것을 보내는 방식이다.


특히, 네트워크 지연이 있는 상황에서 하나씩 보내면서 매번 네트워크를 타는 것보다, 쌓아놓고 보내는 횟수를 줄이는 것이 도움이 되기도 한다. (상황에 따른 판단 후 선택 필요)


컨슈머가 메시지를 취득할 때는, 취득 대상의 토픽과 파티션의 Current Offset 위치에서 시작한다. 컨슈머가 읽으려는 요청 간격에 따라 메시지를 소비하고, offset 값을 갱신하면 된다.

메시지를 하나만 취득하면 계속 읽으면서 current offset 값을 갱신하면 되고, 일정 간격을 두고 읽는 경우에는 한 번에 읽은 만큼의 offset을 갱신하면 된다.


![img2-6-1](/chapter02/img/2-6-1.png)


![img2-6-2](/chapter02/img/2-6-2.png)



---
## 2.4.2 컨슈머의 롤백
컨슈머는 offset commit을 통해 지속적으로 메시지를 취득하는데, 이를 이용해 처리 실패나 재시도 로직을 실현하기도 한다.


![img2-7-1](/chapter02/img/2-7-1.png)


![img2-7-2](/chapter02/img/2-7-2.png)


위 이미지의 과정에서 주의해야할 점은, commit offset까지 돌아가서 재개할 때의 대처는 후속 애플리케이션에게 맡긴다는 것이다.


만약, 이미 메시지를 처리한 상태에서 commit 하기 직전에 장애가 발생했다면, 메시지 재처리 시 중복 소비가 일어날 수 있다. 그렇기에 메시지 중복 처리(or 허용)이 필요하다.


해당 재시도는 At Least Once로 송신하는 구조이며, 컨슈머의 고장이나 장애를 감지하여 재시도하는 메커니즘이 잘 구비되어 있으므로 사용하도록 하자.


---
## 2.4.3 메시지 전송 시 파티셔닝
프로듀서에서 송신하는 메시지를 어떻게 파티션으로 보낼지 결정하는 파티셔닝(분할) 기능이 있다.


보내는 메시지에 포함된 Key와 Value 중에 Key의 명시적인 지정 여부에 따라 다음 두 가지 패턴 로직으로 송신된다.


1. Key의 해시 값을 사용한 송신
    - 메시지의 Key를 명시적으로 지정하여, Key에 따라 송신처 파티션을 결정한다.
    - 동일한 Key를 가진 메시지는 동일한 ID를 가진 파티션에 송신된다.


2. 라운드 로빈에 의한 송신 (Kafka 2.3 이하)
    - 메시지 Key를 지정하지 않고 null 로 한 경우, 여러 파티션으로의 메시지 송신을 라운드 로빈 방식으로 실행한다.


3. StikyPartitioner / UniformStickyPartitioner (Kafka 2.4 이상)
    - 라운드 로빈 방식의 단점 (배치 크기 감소로 인한 오버헤드 급증) 개선을 위해 도입됨
    - 내부 파티션 랜덤 선택 후, 배치 단위 sticky하게 처리 + 필요시 순환 로직 조합(기존 라운드 로빈처럼)
    - 배치 당 파티션 변경 횟수를 크게 줄여 직렬화/네트워크 오버헤드를 절감하면서 파티션 사이의 균등 분산을 유지함



### 사용 예시와 주의 사항
예를 들어, 웹의 액세스 로그를 송신할 때 발신지 IP 주소에 따라 파티션별로 나누어 던지는 경우, 로그 안에서 "발신지 IP 주소"를 Key로 설정할 수 있다.


해시에 의한 파티셔닝을 이용할 때, 동일 Key를 가진 메시지는 동일 컨슈머에서 처리하는 식으로 순서를 제어할 수 있다.


그러나 파티셔닝을 이용하는 경우는 데이터 편차에 따른 파티션의 편향에도 주의를 기울여야 한다. 특정 파티션에 편향이 발생하면 리소스를 부분적으로 사용하지 못해 효율적이지 않고, 처리 속도 문제도 고려해야 한다.


### 브로커의 데이터 보관 기간
카프카는 수신한 메시지를 디스크에 영속화하기 때문에, 컨슈머가 과거의 데이터도 읽을 수 있다.


그러나 현실적으로 스토리지 용량 제한이 있기 때문에 두 가지 정책을 통해 데이터를 삭제한다.


1. 오래된 메시지 삭제
    - 축적된 메시지 중, 오래된 것 부터 삭제
    - 삭제 트리거에 대해서는, 메시지 취득 후 경과 시간 or 데이터 크기 (두 가지 중에 설정 가능)
    - 데이터 취득 후 경과 시간을 트리거로 하는 경우, hour/min/ms 등의 단위로 지정할 수 있고 해당 시간보다 오래된 데이터가 삭제된다.
    - 데이터 크기를 트리거로 한 경우, 축적된 데이터가 지정한 크기보다 커질 때 데이터가 삭제된다.


2. 압축
    - 최신 Key의 데이터를 남겨두고 중복하는 Key의 오래된 메시지가 삭제된다.
    - 동일한 Key에 대해서, 항상 최신의 value 만 얻을 수 있다면 되는 상황에서 사용한다.
    - 특별한 예씨로, RDBMS의 insert 또는 update 된 레코드를 카프카에서도 수신하고 있는 경우, update 이후의 최신 값만 취득해도 될 수 있다.
    - 이렇게 압축을 설정하면, 디스크 용량과 IO를 효율적으로 이용하면서 각 Key에 대해서 최신 정보를 포함하는 레코드를 유지할 수 있다.


---
## 2.5 데이터의 견고성을 높이는 복제 구조
카프카는 수신한 메시지를 잃지 않기 위해 복제(Replication) 구조를 갖추고 있다.


일반적으로, 여러 대의 브로커에 토픽 구성 파티션과 레플리카가 배치되는 구조이다.


파티션은 단일 or 여러 개의 레플리카로 구성되어 토픽 단위로 레플리카 수를 지정할 수 있다.


또한, 레플리카 중 하나는 Leader이며, 나머지는 Follower이다. Follower는 Leader로부터 메시지를 계속 취득하여 복제 상태를 유지한다. 다만, Producer/Consumer 와의 데이터 교환은 Leader가 맡는다.


![img2-11](/chapter02/img/2-11.png)


### 메시지 순서 보증
카프카의 분산 메시징 메커니즘에서, 메시지를 produce한 순서대로 소비할 수 있을까? 


단일 파티션에 한정한다면 메시지를 순서대로 처리할 수 있다. 그러나 단일 파티션으로 고정하는 것은 카프카의 장점을 제대로 살릴 수 없기에 대안을 생각해야 한다.


먼저, 해시에 의한 분할로 같은 Key에 대해서 같은 파티션에 들어가게하면 카테고리별로 순서를 제어할 수 있다.


또한, 브로커에서 완전 정렬을 시도할 것인지(외부 시퀀서 등) or 컨슈머 측에서 자체 정렬을 구현할 것인지(버퍼 윈도우 등) 서비스 특징에 따라 맞는 방안을 고민해야 한다.



---
## 2.5.1 레플리카의 동기 상태
Leader Replica의 복제 상태를 유지하고 있는 레플리카를 In-Sync Replica(ISR) 라고 한다.


모든 레플리카가 ISR로 되어 있지 않은 파티션을 Under Replicated Partitions 라고 부른다. 


또한 복제 수와는 독립적으로 최소 ISR 수(`min.insync.replica`) 설정이 가능하며,
고장 등으로 인한 일시적인 동기 지연을 허용하기 때문에 전체 읽고 쓰기를 계속할 수 있다.


---
## 2.5.2 복제 완료 최신 오프셋(High WaterMark)
복제 사용시 오프셋 관리를 할 때, LEO(Log-End-Offset) 외에도 High Watermark라는 개념이 있다.
이는 복제가 완료된 오프셋이며, LEO와 동일하거나 오래된 오프셋을 나타낸다. 컨슈머는 High Watermark 까지 기록된 메시지를 취득할 수 있다.


---
## 2.5.3 프로듀서의 메시지 도달 보증 수준
복제에 대해 Ack 설정도 중요하다. 브로커에서 프로듀서로 메시지가 송신된 것을 나타내는 Ack를 어느 타이밍에 송신할 것인지 제어하는 것은 큰 영향을 준다.
    - 성능과 내결함성(브로커 서버 고장 시 데이터 분실 방지 등)에 영향을 주는 옵션


### Ack 설정
Ack 설정은 다음 3가지로 가능하다.


1. `0` : 프로듀서는 메시지 송신 시 Ack를 기다리지 않고 다음 메시지를 송신한다.
2. `1` : Leader Replica 에 메시지가 전달되면 Ack를 반환한다.
3. `all` : 모든 ISR 수만큼 복제되면 Ack를 반환한다.


---
## 2.5.4 In-Sync-Replica 와 Ack=all, 쓰기 계속성의 관계
복제 수와 별도로, 최소 ISR 수를 제어하면서 여러 상황을 따져볼 수 있다. ISR과 Ack 설정에 따라 프로듀서의 쓰기 동작 예를 두 가지 패턴으로 설명할 수 있다.


1. `min.insync.replicas=3`, `Ack=all`


2. `min.insync.replicas=2`, `Ack=all`



---
## 2.6 정리
다음은 2장에서 정리한 전체 카프카 구성도이다.


![img2-15](/chapter02/img/2-15.png)


위 내용을 바탕으로 카프카의 특징과 장점을 요약하면 다음과 같다.


1. Scale-out 구성: 중계 브로커를 증대하여 전체 처리량을 늘릴 수 있다.
2. 데이터의 Disk 영속화: 장기간의 과거 데이터도 저장, 재취득 가능
3. 다양한 연계 제품: 프로듀서/컨슈머 API를 구현한 다양한 OSS 존재
4. 메시지 도달 보증: Ack 와 Offset commit 으로 메시지가 제대로 송수신되었음을 확인하고, 실패 시 재시도를 허용한다.